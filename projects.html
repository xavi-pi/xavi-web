<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">
    <title>xavier pineda</title>
    <link rel="stylesheet" href="style.css">


<body>

<div class="sidebar">
    <div class="line"></div>
    <div class="dot_link scroll_to">
        <a class="link" href="#projects_1"></a>
        <a class="link" href="#projects_2"></a>
        <a class="link" href="#projects_3"></a>
        <a class="link" href="#projects_4"></a>
        <a class="link" href="#projects_5"></a>
        <a class="link" href="#projects_6"></a>
        <a class="link" href="#projects_7"></a>
        <a class="link" href="#projects_8"></a>
        <a class="link" href="#projects_9"></a>
        <a class="link" href="#projects_10"></a>
        <a class="link" href="#projects_11"></a>
        <a class="link" href="#projects_12"></a>
        <a class="link" href="#projects_13"></a>
        <a class="link" href="#projects_14"></a>
        <a class="link" href="#projects_15"></a>
        <a class="link" href="#projects_16"></a>
        <a class="link" href="#projects_17"></a>
        <a class="link" href="#projects_18"></a>
        <a class="link" href="#projects_19"></a>
        <a class="link" href="#projects_20"></a>
    </div>
</div>
<nav>
    <a href="#" class="nav-name">
        <h1> XAVIER PINEDA</h1>
    </a>
    <div class="red_line line_none"></div>
    <div class="wrap_nav">
        <ul class="main_nav">
            <li>
                <a href="./index.html">HELLO!</a>
            </li>
            <li>
                <a class="active_nav_menu" href="./projects.html">PROJECTS</a>
            </li>
            <li>
                <a href="./photography.html">PHOTOGRAPHY</a>
            </li>
<!--             <li>
                <a href="./blog.html">BLOG</a>
            </li> -->
        </ul>
       <span class="social_networks">
            <a href="https://www.linkedin.com/in/xavierpineda/" target="_blank">
               <img src="img/icon/linkedin-64.ico" alt="linkedin">
            </a>
            <a href="https://github.com/xavi-pi" target="_blank">
              <img src="img/icon/github-6-64.ico" alt="github">
            </a>
        </span>
        </span>
    </div>
</nav>
<section class="projects" data-sr>
    <div class="container_projects_item section" id="projects_1">
        <img src="./img/projects/fisher_corpus_pipeline.png" alt="Fisher Corpus pipeline visualization">
        <h2>Fisher Corpus Data Pipeline</h2>
        <h4>June 2025 - Present</h4>
        <p>Engineered end-to-end data processing pipeline for the <strong>Fisher Corpus</strong> (1,960 hours of conversational speech). Implemented <strong>PyTorch-based</strong> audio segmentation, automated text normalization, and cloud-optimized processing that reduced preprocessing time from days to hours while maintaining 16kHz audio quality standards.</p>
    </div>
    <div class="container_projects_item section" id="projects_2">
        <img src="./img/projects/multimodal_conversation_analysis.png" alt="Multi-modal conversation analysis dashboard">
        <h2>Multi-Modal Conversation Analysis Pipeline</h2>
        <h4>June 2025 - Present</h4>
        <p>Built a multi-modal conversation analysis pipeline using <strong>Whisper ASR</strong> and custom temporal alignment algorithms. Engineered automated processing of experimental AI dialogues with <strong>93% accuracy</strong> in speaker identification and turn segmentation across 200+ conversation sessions.</p>
    </div>
    <div class="container_projects_item section" id="projects_3">
        <img src="./img/projects/genai_hallucination_analysis.png" alt="Hallucination analysis comparison chart">
        <h2>Generative AI Hallucination Analysis</h2>
        <h4>June 2025 - Present</h4>
        <p>Led comprehensive hallucination analysis comparing <strong>GPT-4o</strong> and <strong>Gemini</strong> speech generation across 888+ samples. Developed multi-metric evaluation framework measuring transcription accuracy (<strong>WERP</strong>), hallucination patterns (<strong>DNI</strong>, <strong>COE</strong>), and length-based metrics, revealing actionable insights for customers.</p>
    </div>
    <div class="container_projects_item section" id="projects_4">
        <img src="./img/projects/genai_summarization_evaluation.png" alt="Summarization evaluation metrics">
        <h2>Gen AI Summarization Evaluation System</h2>
        <h4>June 2025 - Present</h4>
        <p>Developed a multi-metric evaluation system for Gen AI summarization models. Engineered a scalable assessment framework combining semantic (<strong>BERTScore</strong>), factual (<strong>FactCC</strong>), and structural (<strong>Entity Grid</strong>) analysis, with a proof-of-concept implementation using <strong>Llama-3</strong> on the <strong>CNN/DailyMail</strong> corpus.</p>
    </div>
    <div class="container_projects_item section" id="projects_5">
        <img src="./img/projects/live_transcription_evaluation.png" alt="Live transcription evaluation dashboard">
        <h2>Live Transcription Model Evaluation</h2>
        <h4>June 2025 - Present</h4>
        <p>Led performance evaluation of the <strong>Deepgram Nova-2</strong> live transcription model using the <strong>FLEURS</strong> database. Analyzed 648 speech samples (14.3K+ words) using a custom evaluation framework, quantifying model accuracy through detailed <strong>WER</strong> analysis and multi-percentile performance distribution (P50/P90/P95/P99).</p>
    </div>
    <div class="container_projects_item section" id="projects_6">
        <img src="./img/projects/asr_robustness_benchmarking.png" alt="ASR robustness testing framework">
        <h2>ASR Robustness Benchmarking Framework</h2>
        <h4>June 2025 - Present</h4>
        <p>Engineered a comprehensive ASR robustness evaluation framework across 114 scenarios. Developed a multi-category testing pipeline (social gatherings, accents, environmental noise) using 4 major datasets (<strong>LibriSpeech</strong>, <strong>CHiME-6</strong>, <strong>AMI</strong>, <strong>Common Voice</strong>) to assess model performance (<strong>Gemini</strong>, <strong>ChatGPT</strong>, <strong>Nova</strong>, <strong>Whisper</strong>) in real-world conditions.</p>
    </div>
    <div class="container_projects_item section" id="projects_7">
        <img src="./img/projects/automated_multilingual_qa.png" alt="Automated QA system architecture">
        <h2>Automated Multilingual Beta QA System</h2>
        <h4>June 2025 - Present</h4>
        <p>Architected an end-to-end quality assurance system for multilingual AI beta testing. Engineered an automated pipeline combining <strong>AWS Bedrock</strong> LLMs, <strong>Whisper ASR</strong>, and <strong>WavLM</strong> speaker verification to detect voice drift and anomalies with real-time SNS notifications, reducing manual review time by <strong>70%</strong>.</p>
    </div>
    <div class="container_projects_item section" id="projects_8">
        <img src="./img/projects/crosslingual_translation_evaluation.png" alt="Cross-lingual translation metrics">
        <h2>Cross-Lingual Translation Evaluation</h2>
        <h4>June 2025 - Present</h4>
        <p>Led cross-lingual translation evaluation comparing <strong>GPT-4/5</strong>, <strong>Gemini 2.5/3.0</strong>, and <strong>Claude</strong> models across 5 languages (DE/FR/ES/IT/EN). Achieved <strong>46.34 BLEU</strong> score using a custom evaluation framework and reduced unusable API responses from 22% to &lt;1% through enhanced prompt engineering and retry logic.</p>
    </div>
    <div class="container_projects_item section" id="projects_9">
        <img src="./img/projects/hitl_automation_framework.png" alt="HITL automation workflow">
        <h2>Human-In-The-Loop Automation Framework</h2>
        <h4>June 2025 - Present</h4>
        <p>Developed a comprehensive HITL automation framework for voice quality testing. Created a scalable pipeline combining audio preprocessing (normalization, stitching), test deployment, and statistical analysis tools that streamlined evaluation of 1,000+ audio samples across multiple locales with automated result aggregation.</p>
    </div>
    <div class="container_projects_item section" id="projects_10">
        <img src="./img/projects/aws_transcribe_integration.png" alt="AWS Transcribe integration diagram">
        <h2>AWS Transcribe Integration for API Benchmarking</h2>
        <h4>January 2023 - June 2025</h4>
        <p>Architected and implemented AWS Transcribe integration for API Benchmarking Service using Python. Engineered hybrid streaming/batch processing pipeline with <strong>Lambda/SQS</strong> to handle 25+ concurrent audio files, reducing transcription latency by <strong>60%</strong> while maintaining <strong>85%+ accuracy</strong> against human benchmarks.</p>
    </div>
    <div class="container_projects_item section" id="projects_11">
        <img src="./img/projects/ml_model_benchmarking.png" alt="ML model benchmarking workflow">
        <h2>ML Model Benchmarking Framework</h2>
        <h4>January 2023 - June 2025</h4>
        <p>Architected end-to-end ML model benchmarking framework using <strong>AWS SageMaker</strong> and <strong>S3</strong>. Standardized deployment procedures for <strong>HuggingFace</strong> models across 3+ teams, reducing setup time by <strong>70%</strong> while implementing <strong>KMS encryption</strong> and automated resource optimization for GPU instances.</p>
    </div>
    <div class="container_projects_item section" id="projects_12">
        <img src="./img/projects/speech_translation_benchmarking.png" alt="Speech translation pipeline">
        <h2>Speech Translation Benchmarking Initiative</h2>
        <h4>January 2023 - June 2025</h4>
        <p>Led end-to-end speech translation benchmarking initiative across 4 language pairs. Engineered automated evaluation pipeline using <strong>Whisper</strong> and <strong>Meta Seamless</strong> models with multiple metrics (<strong>BLEU</strong>, <strong>chrF</strong>, <strong>COMET</strong>, <strong>BLASER2.0</strong>), reducing evaluation time by <strong>85%</strong> while ensuring standardized ASR normalization.</p>
    </div>
    <div class="container_projects_item section" id="projects_13">
        <img src="./img/projects/ml_quality_control_automation.png" alt="ML quality control system">
        <h2>ML-Driven Quality Control Automation</h2>
        <h4>January 2023 - June 2025</h4>
        <p>Engineered a semantic similarity validation system using <strong>spaCy</strong> models and a <strong>Random Forest classifier</strong> (<strong>94% accuracy</strong>) to filter false-positive transcription errors. Reduced manual data review volume by <strong>79.8%</strong> across FireTV/Alexa projects, saving an estimated <strong>$75,000 annually</strong> and compressing validation timelines from weeks to days.</p>
    </div>
    <div class="container_projects_item section" id="projects_14">
        <img src="./img/projects/genai_productivity_tools.png" alt="GenAI productivity tools">
        <h2>Internal GenAI Productivity Tools</h2>
        <h4>January 2023 - June 2025</h4>
        <p>Prototyped and shipped <strong>custom GPTs</strong> and "prompt packs" to automate routine engineering on-call support tasks. Reduced on-call ticket volume from 7 to 4 requests per week and halved the ideation time for new test cases (4 days to 2 days).</p>
    </div>
    <div class="container_projects_item section" id="projects_15">
        <img src="./img/projects/synthetic_data_testing.png" alt="Synthetic data generation">
        <h2>Accelerated Testing via Synthetic Data Generation</h2>
        <h4>January 2023 - June 2025</h4>
        <p>Led research into using <strong>GPT-J</strong>, <strong>StableLLM</strong>, and <strong>GPT-2</strong> to generate synthetic evaluation datasets and automate text tokenization. Increased the velocity of experimental benchmarks by <strong>30% per quarter</strong>, removing dependencies on costly human-annotated datasets.</p>
    </div>
    <div class="container_projects_item section" id="projects_16">
        <img src="./img/projects/stress_test_datasets.png" alt="Stress test evaluation datasets">
        <h2>Stress-Test Evaluation Datasets</h2>
        <h4>October 2021 - January 2023</h4>
        <p>Created specialized datasets targeting <strong>phonological and syntactic complexity</strong> to identify failure modes in Alexa's single-stack ASR. Analysis and subsequent tuning led to a <strong>6.3% performance gain</strong> in handling complex user queries across multiple locales.</p>
    </div>
    <div class="container_projects_item section" id="projects_17">
        <img src="./img/projects/language_drift_monitoring.png" alt="Language drift monitoring dashboard">
        <h2>Language Drift Monitoring System</h2>
        <h4>October 2021 - January 2023</h4>
        <p>Architected a data pipeline to detect emerging linguistic trends and vocabulary shifts on a weekly and quarterly basis, ensuring ASR lexicons stayed current with evolving user speech patterns.</p>
    </div>
    <div class="container_projects_item section" id="projects_18">
        <img src="./img/projects/etl_pipeline.png" alt="Data pipeline architecture">
        <h2>Content Database & ETL Pipeline</h2>
        <h4>August 2018 - October 2021</h4>
        <p>Designed and implemented a content database with an automated <strong>ETL pipeline</strong>, reducing project delivery cycles by <strong>40-80%</strong> and standardizing data ingestion for linguistic research. Scripted custom Python tooling to incorporate <strong>5+ novel quality metrics</strong> into dataset creation workflows.</p>
    </div>
    <div class="container_projects_item section" id="projects_19">
        <img src="./img/projects/artemis_datasets.png" alt="Artemis I partnership logo">
        <h2>Artemis I Elicitation Datasets</h2>
        <h4>August 2018 - October 2021</h4>
        <p>Created user interaction test sets for the <strong>Artemis I</strong> partnership (NASA, Lockheed Martin), capturing realistic user query patterns to update ASR models with mission-specific vocabulary for the launch event.</p>
    </div>
    <div class="container_projects_item section" id="projects_20">
        <img src="./img/projects/linguistic_ab_experiments.png" alt="Linguistic A/B experiment results">
        <h2>Linguistic A/B Experiments</h2>
        <h4>August 2018 - October 2021</h4>
        <p>Structured and executed A/B tests to validate new elicitation tools, utilizing data-driven insights to optimize field research methodologies.</p>
    </div>

</section>
<!--<script src="js/all.js"></script>-->
</body>
</html>
